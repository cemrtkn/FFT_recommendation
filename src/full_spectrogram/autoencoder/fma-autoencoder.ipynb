{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-13T15:07:35.113501Z",
     "iopub.status.busy": "2025-02-13T15:07:35.113227Z",
     "iopub.status.idle": "2025-02-13T15:07:37.192605Z",
     "shell.execute_reply": "2025-02-13T15:07:37.191945Z",
     "shell.execute_reply.started": "2025-02-13T15:07:35.113478Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from data_loader import SpectLoader\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import ReLU\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T15:07:37.193898Z",
     "iopub.status.busy": "2025-02-13T15:07:37.193527Z",
     "iopub.status.idle": "2025-02-13T15:07:37.197523Z",
     "shell.execute_reply": "2025-02-13T15:07:37.196741Z",
     "shell.execute_reply.started": "2025-02-13T15:07:37.193868Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_path = '/kaggle/input/fma-small-mel-spectrograms/fma_small_specs/spectrograms.h5'\n",
    "spec_minmax_scaler_path = '/kaggle/input/fma-small-mel-spectrograms/scaler.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T15:07:37.198898Z",
     "iopub.status.busy": "2025-02-13T15:07:37.198649Z",
     "iopub.status.idle": "2025-02-13T15:07:49.922201Z",
     "shell.execute_reply": "2025-02-13T15:07:49.921397Z",
     "shell.execute_reply.started": "2025-02-13T15:07:37.198878Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_range': (-1, 1), 'min_': -100.0, 'scale_': 212.16319274902344}\n",
      "feature_range\n",
      "min_\n",
      "scale_\n"
     ]
    }
   ],
   "source": [
    "paths = {\n",
    "        \"data_path\": data_path,\n",
    "        \"scaler_path\": spec_minmax_scaler_path\n",
    "    }\n",
    "\n",
    "pprocessor = SpectLoader(paths, batch_size=32)\n",
    "train_keys, val_keys, test_keys = pprocessor.split_data()\n",
    "pprocessor.setup_pipeline(scaler_type=\"normalizer\",load_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T15:07:49.923864Z",
     "iopub.status.busy": "2025-02-13T15:07:49.923512Z",
     "iopub.status.idle": "2025-02-13T15:07:49.928658Z",
     "shell.execute_reply": "2025-02-13T15:07:49.927870Z",
     "shell.execute_reply.started": "2025-02-13T15:07:49.923830Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 646)\n"
     ]
    }
   ],
   "source": [
    "sample1_shape = pprocessor.spect_data[pprocessor.train_keys[0]]['spectrogram'].shape\n",
    "input_shape=(1, sample1_shape[0], sample1_shape[1])\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T15:07:49.929635Z",
     "iopub.status.busy": "2025-02-13T15:07:49.929447Z",
     "iopub.status.idle": "2025-02-13T15:07:49.946489Z",
     "shell.execute_reply": "2025-02-13T15:07:49.945743Z",
     "shell.execute_reply.started": "2025-02-13T15:07:49.929618Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *shape):\n",
    "        super().__init__()\n",
    "        self.shape = shape  # The target shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(*self.shape)\n",
    "        return x\n",
    "\n",
    "class Trim(nn.Module):\n",
    "    def __init__(self, *shape):\n",
    "        super().__init__()\n",
    "        self.shape = shape  # The target shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.narrow(2,0,self.shape[0][1])\n",
    "        x = x.narrow(3,0,self.shape[0][2])\n",
    "        return x\n",
    "\n",
    "class EncoderConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, last_layer, stride = 1):\n",
    "        super().__init__()\n",
    "        if last_layer:\n",
    "            self.conv = nn.Sequential(\n",
    "                            nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 2),\n",
    "                            nn.Flatten())\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                            nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 2),\n",
    "                            nn.LeakyReLU(0.01))\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        return out\n",
    "\n",
    "class DecoderConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, last_layer, stride = 1):\n",
    "        super().__init__()\n",
    "        if last_layer:\n",
    "            self.conv = nn.Sequential(\n",
    "                            nn.ConvTranspose2d(in_channels, 1, kernel_size = 3, stride = stride, padding = 1),\n",
    "                            )\n",
    "                \n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                            nn.ConvTranspose2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n",
    "                            nn.LeakyReLU(0.01))\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T15:14:38.735406Z",
     "iopub.status.busy": "2025-02-13T15:14:38.735113Z",
     "iopub.status.idle": "2025-02-13T15:14:38.743648Z",
     "shell.execute_reply": "2025-02-13T15:14:38.742875Z",
     "shell.execute_reply.started": "2025-02-13T15:14:38.735386Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, channels, input_shape):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "        # encoder\n",
    "        self.encoder = nn.ModuleList()\n",
    "        for layer_id, out_channels in enumerate(self.channels):            \n",
    "            conv_layer = self._make_conv_layer(EncoderConvBlock, layer_id, out_channels=out_channels)\n",
    "            self.encoder.append(conv_layer)\n",
    "            \n",
    "        # bottleneck\n",
    "        latent_size = self._calculate_flatten_size()\n",
    "        bottleneck = nn.Linear(latent_size, 1024)\n",
    "        self.encoder.append(bottleneck)\n",
    "\n",
    "        self.decoder = nn.ModuleList()\n",
    "        upscaler = nn.Sequential(\n",
    "                        nn.Linear(1024, latent_size),\n",
    "                        Reshape((-1, 64, 18, 43)) # special for size 41984\n",
    "                        )\n",
    "        self.decoder.append(upscaler)\n",
    "        for layer_id, in_channels in enumerate(self.channels[::-1]):\n",
    "            conv_layer = self._make_conv_layer(DecoderConvBlock, layer_id, in_channels=in_channels)\n",
    "            self.decoder.append(conv_layer)\n",
    "        self.decoder.append(Trim(self.input_shape))\n",
    "\n",
    "    def _make_conv_layer(self, block, layer_id, in_channels=0, out_channels=0, last_layer_bool=False, stride=2):\n",
    "        if layer_id == 0: # first layer\n",
    "            if block == EncoderConvBlock:\n",
    "                in_channels = 1 \n",
    "            elif block == DecoderConvBlock:\n",
    "                out_channels = 64\n",
    "        else:\n",
    "            if block == EncoderConvBlock:\n",
    "                in_channels = self.channels[layer_id-1]\n",
    "            if layer_id == len(self.channels)-1: # last layer\n",
    "                last_layer_bool = True\n",
    "            elif block == DecoderConvBlock:\n",
    "                out_channels = self.channels[::-1][layer_id+1] \n",
    "            \n",
    "            \n",
    "        layers = []\n",
    "        layers.append(block(in_channels, out_channels, last_layer=last_layer_bool, stride=stride))\n",
    "    \n",
    "        return nn.Sequential(*layers)\n",
    "    def _calculate_flatten_size(self):\n",
    "        x = torch.zeros(1, *self.input_shape)\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "        return x.numel()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "        for layer in self.decoder:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T15:07:49.966473Z",
     "iopub.status.busy": "2025-02-13T15:07:49.966259Z",
     "iopub.status.idle": "2025-02-13T15:07:50.348574Z",
     "shell.execute_reply": "2025-02-13T15:07:50.347702Z",
     "shell.execute_reply.started": "2025-02-13T15:07:49.966455Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 256, 646]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "for x, y in pprocessor.batch_generator(train_keys, batch_size=16):\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T15:14:41.896445Z",
     "iopub.status.busy": "2025-02-13T15:14:41.896127Z",
     "iopub.status.idle": "2025-02-13T15:14:42.887000Z",
     "shell.execute_reply": "2025-02-13T15:14:42.886249Z",
     "shell.execute_reply.started": "2025-02-13T15:14:41.896417Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Used CUDA memory: 977.204736 MB\n"
     ]
    }
   ],
   "source": [
    "model = AutoEncoder([32,64,64,64], input_shape)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"1: Used CUDA memory: {torch.cuda.memory_allocated() / 1e6} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T15:14:49.518856Z",
     "iopub.status.busy": "2025-02-13T15:14:49.518516Z",
     "iopub.status.idle": "2025-02-13T15:14:49.524710Z",
     "shell.execute_reply": "2025-02-13T15:14:49.523804Z",
     "shell.execute_reply.started": "2025-02-13T15:14:49.518827Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): EncoderConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
       "          (1): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): EncoderConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
       "          (1): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): EncoderConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
       "          (1): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): EncoderConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
       "          (1): Flatten(start_dim=1, end_dim=-1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): Linear(in_features=49536, out_features=1024, bias=True)\n",
       "  )\n",
       "  (decoder): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=49536, bias=True)\n",
       "      (1): Reshape()\n",
       "    )\n",
       "    (1-2): 2 x Sequential(\n",
       "      (0): DecoderConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): DecoderConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): DecoderConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvTranspose2d(32, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): Trim()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T15:19:02.315876Z",
     "iopub.status.busy": "2025-02-13T15:19:02.315547Z",
     "iopub.status.idle": "2025-02-13T15:19:03.456129Z",
     "shell.execute_reply": "2025-02-13T15:19:03.455274Z",
     "shell.execute_reply.started": "2025-02-13T15:19:02.315849Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 256, 646])\n",
      "Input Min value: -0.07235373556613922, Max value: 0.8977598547935486\n",
      "Output Min value: -0.3352450132369995, Max value: -0.21468940377235413\n",
      "torch.Size([8, 1, 256, 646])\n",
      "Input Min value: 0.06907837092876434, Max value: 0.9608559012413025\n",
      "Output Min value: -0.3352465331554413, Max value: -0.21471579372882843\n",
      "torch.Size([8, 1, 256, 646])\n",
      "Input Min value: -0.1920861154794693, Max value: 0.8943788409233093\n",
      "Output Min value: -0.3352445960044861, Max value: -0.21468240022659302\n",
      "torch.Size([8, 1, 256, 646])\n",
      "Input Min value: -0.12363727390766144, Max value: 0.9752476811408997\n",
      "Output Min value: -0.33527040481567383, Max value: -0.2146971970796585\n",
      "torch.Size([8, 1, 256, 646])\n",
      "Input Min value: -0.18928714096546173, Max value: 0.9290701746940613\n",
      "Output Min value: -0.335260808467865, Max value: -0.21468393504619598\n",
      "torch.Size([8, 1, 256, 646])\n",
      "Input Min value: -0.08061899244785309, Max value: 0.9168463349342346\n",
      "Output Min value: -0.33524343371391296, Max value: -0.21470195055007935\n",
      "torch.Size([8, 1, 256, 646])\n",
      "Input Min value: 0.015633033588528633, Max value: 0.9101267457008362\n",
      "Output Min value: -0.3352423310279846, Max value: -0.2147039920091629\n",
      "torch.Size([8, 1, 256, 646])\n",
      "Input Min value: 0.00858442671597004, Max value: 0.9085084795951843\n",
      "Output Min value: -0.3352397382259369, Max value: -0.21470895409584045\n",
      "torch.Size([8, 1, 256, 646])\n",
      "Input Min value: 0.03572933375835419, Max value: 0.8958345055580139\n",
      "Output Min value: -0.3352421820163727, Max value: -0.21469223499298096\n",
      "torch.Size([8, 1, 256, 646])\n",
      "Input Min value: -0.06273014843463898, Max value: 0.8504109978675842\n",
      "Output Min value: -0.3352372348308563, Max value: -0.2146698385477066\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for x, y in pprocessor.batch_generator(train_keys, batch_size=8):\n",
    "    outputs = model(x)\n",
    "    print(outputs.shape)\n",
    "    i_min_val, i_max_val= x.min(), x.max()\n",
    "    o_min_val, o_max_val= outputs.min(), outputs.max()\n",
    "    \n",
    "    print(f\"Input Min value: {i_min_val.item()}, Max value: {i_max_val.item()}\")\n",
    "    print(f\"Output Min value: {o_min_val.item()}, Max value: {o_max_val.item()}\")\n",
    "    counter+=1\n",
    "    if counter == 10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T15:19:49.264040Z",
     "iopub.status.busy": "2025-02-13T15:19:49.263699Z",
     "iopub.status.idle": "2025-02-13T15:20:27.670994Z",
     "shell.execute_reply": "2025-02-13T15:20:27.669917Z",
     "shell.execute_reply.started": "2025-02-13T15:19:49.264013Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1634710133075714\n",
      "0.19614450633525848\n",
      "0.17831425368785858\n",
      "0.13848836719989777\n",
      "0.14491181075572968\n",
      "0.1460307240486145\n",
      "0.13479246199131012\n",
      "0.1204211637377739\n",
      "0.16324685513973236\n",
      "0.16541483998298645\n",
      "0.12994372844696045\n",
      "0.16480106115341187\n",
      "0.15121157467365265\n",
      "0.15274761617183685\n",
      "0.16316798329353333\n",
      "0.13580799102783203\n",
      "0.15387894213199615\n",
      "0.12811382114887238\n",
      "0.12070447206497192\n",
      "0.11751474440097809\n",
      "0.11143780499696732\n",
      "0.12368609756231308\n",
      "0.0899212434887886\n",
      "0.09532462060451508\n",
      "0.11038666218519211\n",
      "0.08583490550518036\n",
      "0.07383821159601212\n",
      "0.07402022927999496\n",
      "0.06818632036447525\n",
      "0.07654598355293274\n",
      "0.08013156056404114\n",
      "0.06168756261467934\n",
      "0.04997165873646736\n",
      "0.05843258649110794\n",
      "0.0505002960562706\n",
      "0.044854868203401566\n",
      "0.0414966382086277\n",
      "0.04179038479924202\n",
      "0.035429153591394424\n",
      "0.03388303145766258\n",
      "0.04706977680325508\n",
      "0.028415484353899956\n",
      "0.02351764589548111\n",
      "0.023702073842287064\n",
      "0.02468608133494854\n",
      "0.02200903929769993\n",
      "0.021692760288715363\n",
      "0.021860728040337563\n",
      "0.019796818494796753\n",
      "0.017477689310908318\n",
      "0.01740984432399273\n",
      "0.015683410689234734\n",
      "0.027076927945017815\n",
      "0.014453994110226631\n",
      "0.014289152808487415\n",
      "0.013744895346462727\n",
      "0.013556589372456074\n",
      "0.014621892012655735\n",
      "0.012447726912796497\n",
      "0.011213159188628197\n",
      "0.011860673315823078\n",
      "0.012203413061797619\n",
      "0.009357609786093235\n",
      "0.01154718454927206\n",
      "0.011841297149658203\n",
      "0.011590676382184029\n",
      "0.012834595516324043\n",
      "0.011835510842502117\n",
      "0.010823620483279228\n",
      "0.01010359451174736\n",
      "0.00955843273550272\n",
      "0.009814132004976273\n",
      "0.009924114681780338\n",
      "0.010562708601355553\n",
      "0.010248289443552494\n",
      "0.009101266972720623\n",
      "0.008863503113389015\n",
      "0.009573574177920818\n",
      "0.00810329895466566\n",
      "0.047746192663908005\n",
      "0.009366914629936218\n",
      "0.009386276826262474\n",
      "0.011491961777210236\n",
      "0.01012633927166462\n",
      "0.009182542562484741\n",
      "0.008688190951943398\n",
      "0.008212558925151825\n",
      "0.010221109725534916\n",
      "0.009005622006952763\n",
      "0.008413881063461304\n",
      "0.009410119615495205\n",
      "0.00751433614641428\n",
      "0.009245695546269417\n",
      "0.010151955299079418\n",
      "0.00764043303206563\n",
      "0.009166906587779522\n",
      "0.008130954578518867\n",
      "0.009351111948490143\n",
      "0.009961727075278759\n",
      "0.009012220427393913\n",
      "0.009095787070691586\n",
      "0.008663106709718704\n",
      "0.0073370239697396755\n",
      "0.008009298704564571\n",
      "0.008452527225017548\n",
      "0.008414100855588913\n",
      "0.007033003028482199\n",
      "0.009629192762076855\n",
      "0.008690732531249523\n",
      "0.007730001118034124\n",
      "0.009154768660664558\n",
      "0.008901321329176426\n",
      "0.008855998516082764\n",
      "0.008376150391995907\n",
      "0.008841407485306263\n",
      "0.009536685422062874\n",
      "0.009339719079434872\n",
      "0.009598253294825554\n",
      "0.00954232458025217\n",
      "0.00867167953401804\n",
      "0.007502566557377577\n",
      "0.00808328203856945\n",
      "0.007183113135397434\n",
      "0.008529599756002426\n",
      "0.008387627080082893\n",
      "0.009914325550198555\n",
      "0.007855317555367947\n",
      "0.008320328779518604\n",
      "0.008052879944443703\n",
      "0.008939875289797783\n",
      "0.008217737078666687\n",
      "0.007935854606330395\n",
      "0.008427989669144154\n",
      "0.008963820524513721\n",
      "0.00858748983591795\n",
      "0.00876286905258894\n",
      "0.008603604510426521\n",
      "0.008867296390235424\n",
      "0.008193586952984333\n",
      "0.008743119426071644\n",
      "0.009394320659339428\n",
      "0.008148717693984509\n",
      "0.008050934411585331\n",
      "0.008961251936852932\n",
      "0.008358960039913654\n",
      "0.009736175648868084\n",
      "0.008083845488727093\n",
      "0.00907609611749649\n",
      "0.008348074741661549\n",
      "0.01929040439426899\n",
      "0.007639505434781313\n",
      "0.007838723249733448\n",
      "0.008442667312920094\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c4b99f3bb349>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "criterion = nn.MSELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.7, patience=1)\n",
    "\n",
    "for x, y in pprocessor.batch_generator(train_keys, batch_size=batch_size):\n",
    "        optimizer.zero_grad()    \n",
    "\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, x)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6176370,
     "sourceId": 10033964,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 209915011,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 214038174,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
